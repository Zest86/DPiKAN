{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e04475f-5b04-4f44-91e4-00583b958f78",
   "metadata": {},
   "source": [
    "## Import Libraries and Functions and Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a978bf6c-0334-4ae9-8226-21a7b61bef9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T06:22:14.504481200Z",
     "start_time": "2025-07-28T06:22:14.470584800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Physics Informed Neural Network with Taylor Series\n",
    "import time\n",
    "from utils import *\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import warnings\n",
    "from miscFun import *\n",
    "'''\n",
    "N_INPUT: The number of input bio-z dimensions for one heartbeat\n",
    "N_FEAT: The number of physiological features\n",
    "N_EXT: The number of features extracted by the CNN\n",
    "'''\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'  # 解决 cuBLAS 上下文警告\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 屏蔽部分 TensorFlow/PyTorch 冗余日志（如果存在）\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '2' # 设置可见的 GPU 设备\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"To copy construct from a tensor\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "class Configs:\n",
    "    def __init__(self):\n",
    "        # General parameters\n",
    "        self.begin_order = 1\n",
    "        self.down_sampling_layers = 1 \n",
    "        self.down_sampling_window = 2\n",
    "        self.channel_independence = 1 \n",
    "        self.task_name = 'regression'  # or 'short_term_forecast', 'imputation', 'anomaly_detection', 'regression'\n",
    "        self.seq_len = 32  # Input sequence length\n",
    "        self.label_len = 48  # Label length for forecasting\n",
    "        self.pred_len = 24  # Prediction length\n",
    "        self.e_layers = 2  # Number of encoder layers\n",
    "        self.d_model = 512  # Dimension of the model\n",
    "        self.embed = 'timeF'  # Embedding type, e.g., 'timeF' for time features\n",
    "        self.freq = 's'  # Frequency of the data, e.g., 'h' for hourly data\n",
    "        self.dropout = 0.1  # Dropout rate\n",
    "        self.top_k = 1\n",
    "        self.d_ff = 512  # Dimension of the feedforward network model\n",
    "        self.num_kernels = 6 # Number of kernels in the Inception block\n",
    "        self.enc_in = 32  # Number of input features (for forecasting and imputation)\n",
    "        self.output_attention = False  # Whether to output attention weights\n",
    "        self.factor = 1 # 'attn factor'\n",
    "        self.n_heads = 8  # Number of heads in the multi-head attention\n",
    "        self.moving_avg = 25\n",
    "        self.activation = 'gelu'  # Activation function\n",
    "        self.use_future_temporal_feature = 0 \n",
    "        self.use_norm = 1\n",
    "\n",
    "class DPiKAN(nn.Module):\n",
    "\n",
    "    def __init__(self, configs, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.configs = configs\n",
    "        self.task_name = configs.task_name\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.label_len = configs.label_len\n",
    "        self.down_sampling_window = configs.down_sampling_window\n",
    "        self.channel_independence = configs.channel_independence\n",
    "        self.res_blocks = nn.ModuleList([MultiFrequencyResidual(configs)\n",
    "                                         for _ in range(configs.e_layers)])\n",
    "        self.add_blocks = nn.ModuleList([MultiFrequencyAdd(configs)\n",
    "                                         for _ in range(configs.e_layers)])\n",
    "\n",
    "        self.preprocess = series_decomp(configs.moving_avg)\n",
    "        self.enc_in = configs.enc_in\n",
    "        self.use_future_temporal_feature = configs.use_future_temporal_feature\n",
    "\n",
    "        self.enc_embedding = DataEmbedding_wo_pos(1, configs.d_model, configs.embed, configs.freq,\n",
    "                                                  configs.dropout)\n",
    "        self.layer = configs.e_layers\n",
    "        self.normalize_layers = torch.nn.ModuleList(\n",
    "            [\n",
    "                Normalize(1, affine=True, non_norm=True if configs.use_norm == 0 else False)\n",
    "                for i in range(configs.down_sampling_layers + 1)\n",
    "            ]\n",
    "        )\n",
    "        self.projection_layer = nn.Linear(\n",
    "            configs.d_model, 1, bias=True)\n",
    "        # self.predict_layer = nn.Linear(\n",
    "        #     configs.seq_len,\n",
    "        #     configs.pred_len,\n",
    "        # )\n",
    "        self.predict_layer = nn.Linear(\n",
    "            configs.seq_len,\n",
    "            1,\n",
    "        )\n",
    "\n",
    "    def __multi_level_process_inputs(self, x_enc):\n",
    "\n",
    "        down_pool = torch.nn.AvgPool1d(self.configs.down_sampling_window)\n",
    "        # B,T,C -> B,C,T\n",
    "        x_enc = x_enc.permute(0, 2, 1)\n",
    "        x_enc_ori = x_enc\n",
    "        x_enc_sampling_list = []\n",
    "        x_enc_sampling_list.append(x_enc.permute(0, 2, 1))\n",
    "        for i in range(self.configs.down_sampling_layers):\n",
    "            x_enc_sampling = down_pool(x_enc_ori)\n",
    "            x_enc_sampling_list.append(x_enc_sampling.permute(0, 2, 1))\n",
    "            x_enc_ori = x_enc_sampling\n",
    "        x_enc = x_enc_sampling_list\n",
    "        return x_enc\n",
    "\n",
    "    def regression(self, X, adv_flag=False):\n",
    "        # x_enc, feat_1, feat_2, feat_3 = X[:, :32], X[:, 32], X[:, 33], X[:, 34]\n",
    "        x_enc = X[:, :32]\n",
    "        x_enc = x_enc.unsqueeze(2)\n",
    "        # Moving average\n",
    "        x_enc = self.__multi_level_process_inputs(x_enc)\n",
    "        #\n",
    "        x_list = []\n",
    "        for i, x in zip(range(len(x_enc)), x_enc):\n",
    "            B, T, N = x.size()\n",
    "            # normalize之后维度不对，具体是(B, T, C) -> (B, T, T)，先注释掉了\n",
    "\n",
    "            x = self.normalize_layers[i](x, 'norm')\n",
    "            x = x.permute(0, 2, 1).contiguous().reshape(B * N, T, 1)\n",
    "            x_list.append(x)\n",
    "\n",
    "        enc_out_list = []\n",
    "        # do embedding\n",
    "        for i, x in zip(range(len(x_list)), x_list):\n",
    "            enc_out = self.enc_embedding(x, None)  # [B,T,C]\n",
    "            enc_out_list.append(enc_out)\n",
    "        enc_out_list_numpy = [enc_out.cpu().detach().numpy() for enc_out in enc_out_list]\n",
    "        # Multi-order KAN representation learning\n",
    "\n",
    "        for i in range(self.layer):\n",
    "            enc_out_list = self.res_blocks[i](enc_out_list)\n",
    "            enc_out_list = self.add_blocks[i](enc_out_list)\n",
    "\n",
    "        dec_out = enc_out_list[0]\n",
    "\n",
    "        dec_out = self.projection_layer(dec_out).view(B, -1).contiguous()\n",
    "\n",
    "\n",
    "        dec_out = self.predict_layer(dec_out)\n",
    "        dec_out = dec_out.reshape(B, 1)\n",
    "\n",
    "        # dec_out = self.projection_layer(dec_out)\n",
    "        # 这里dec的normalize也不对，需要重新改一下\n",
    "        # dec_out = self.normalize_layers[0](dec_out, 'denorm')\n",
    "\n",
    "        return dec_out\n",
    "\n",
    "    def regression_net(self, x_enc, feat_1, feat_2, feat_3):\n",
    "        # embedding\n",
    "        return self.regression(torch.cat((x_enc, feat_1, feat_2, feat_3), 1))\n",
    "\n",
    "    def Physics_net(self, feature, feat_1, feat_2, feat_3):\n",
    "        # No need to calculate the gradient of adversarial loss\n",
    "        u = self.regression_net(feature, feat_1, feat_2, feat_3)\n",
    "        u_feat_1 = torch.autograd.grad(u, feat_1,\n",
    "                                       grad_outputs=torch.ones_like(u), create_graph=True)[0].detach()\n",
    "        u_feat_2 = torch.autograd.grad(u, feat_2,\n",
    "                                       grad_outputs=torch.ones_like(u), create_graph=True)[0].detach()\n",
    "        u_feat_3 = torch.autograd.grad(u, feat_3,\n",
    "                                       grad_outputs=torch.ones_like(u), create_graph=True)[0].detach()\n",
    "        pred_physics = (u[:-1, 0]\n",
    "                        + (u_feat_1[:-1, 0] * (feat_1[1:, 0] - feat_1[:-1, 0]))\n",
    "                        + (u_feat_2[:-1, 0] * (feat_2[1:, 0] - feat_2[:-1, 0]))\n",
    "                        + (u_feat_3[:-1, 0] * (feat_3[1:, 0] - feat_3[:-1, 0]))\n",
    "                        )\n",
    "        return u, pred_physics\n",
    "\n",
    "    def forward(self, X, flag, adv_flag):\n",
    "        # flag to show calculate physics loss or not\n",
    "        feature = X[:, :32].clone().detach().requires_grad_(True)\n",
    "        feat_1 = X[:, 32].clone().detach().requires_grad_(True).unsqueeze(1)\n",
    "        feat_2 = X[:, 33].clone().detach().requires_grad_(True).unsqueeze(1)\n",
    "        feat_3 = X[:, 34].clone().detach().requires_grad_(True).unsqueeze(1)\n",
    "\n",
    "        if flag:\n",
    "            u, pred_physics = self.Physics_net(feature, feat_1, feat_2, feat_3)\n",
    "            return u, pred_physics\n",
    "        else:\n",
    "            u = self.regression(X)\n",
    "            return u\n",
    "\n",
    "    def function(self, X, train_out):\n",
    "        u, _ = self.regression(X, adv_flag=True)\n",
    "        pred_loss = torch.mean(torch.square(u - train_out))\n",
    "        return pred_loss\n",
    "\n",
    "\n",
    "\n",
    "class PITN(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(PITN, self).__init__()\n",
    "        self.configs = configs\n",
    "        self.task_name = configs.task_name\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.model = nn.ModuleList([TemporalBlock(configs) for _ in range(configs.e_layers)])\n",
    "        self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
    "                                           configs.dropout)\n",
    "        self.layer = configs.e_layers\n",
    "        self.layer_norm = nn.LayerNorm(configs.d_model)\n",
    "        # add layer_norm_adv for adversarial input\n",
    "        self.layer_norm_adv = nn.LayerNorm(configs.d_model)\n",
    "        self.act = F.gelu\n",
    "        self.dropout = nn.Dropout(configs.dropout)\n",
    "        self.projection = nn.Linear(512, 64)  # Adjust the output dimension for regression\n",
    "        self.decision = nn.Linear(67, 1)\n",
    "        \n",
    "    def regression(self, X, adv_flag=False):\n",
    "        # embedding\n",
    "        x_enc, feat_1, feat_2, feat_3 = X[:, :32], X[:, 32], X[:, 33], X[:, 34]\n",
    "\n",
    "        x_enc = x_enc.unsqueeze(1)\n",
    "        feat_1 = feat_1.unsqueeze(1)\n",
    "        feat_2 = feat_2.unsqueeze(1)\n",
    "        feat_3 = feat_3.unsqueeze(1)\n",
    "\n",
    "        enc_out = self.enc_embedding(x_enc)  # [B, T, C]\n",
    "        # TimesNet\n",
    "        for i in range(self.layer):\n",
    "            if adv_flag:\n",
    "                enc_out = self.layer_norm_adv(self.model[i](enc_out))\n",
    "            else:\n",
    "                enc_out = self.layer_norm(self.model[i](enc_out))\n",
    "        # Output\n",
    "        # the output transformer encoder/decoder embeddings don't include non-linearity\n",
    "        output = self.act(enc_out)\n",
    "        output = self.dropout(output)\n",
    "        # (batch_size, seq_length * d_model)\n",
    "        output = output.reshape(output.shape[0], -1)\n",
    "        hidden_feature = output\n",
    "        output = self.projection(output)  # (batch_size, 64)\n",
    "        output = torch.cat((output, feat_1, feat_2, feat_3), 1)\n",
    "        output = self.decision(output)\n",
    "        return output, hidden_feature\n",
    "\n",
    "    def regression_net(self, x_enc, feat_1, feat_2, feat_3):\n",
    "        # embedding\n",
    "        return self.regression(torch.cat((x_enc, feat_1, feat_2, feat_3), 1))\n",
    "\n",
    "    def Physics_net(self, feature, feat_1, feat_2, feat_3):\n",
    "        # No need to calculate the gradient of adversarial loss\n",
    "        u, _ = self.regression_net(feature, feat_1, feat_2, feat_3)\n",
    "        u_feat_1 = torch.autograd.grad(u, feat_1,\n",
    "                                       grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "        u_feat_2 = torch.autograd.grad(u, feat_2,\n",
    "                                       grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "        u_feat_3 = torch.autograd.grad(u, feat_3,\n",
    "                                       grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "        pred_physics = (u[:-1, 0]\n",
    "                        + (u_feat_1[:-1, 0] * (feat_1[1:, 0] - feat_1[:-1, 0]))\n",
    "                        + (u_feat_2[:-1, 0] * (feat_2[1:, 0] - feat_2[:-1, 0]))\n",
    "                        + (u_feat_3[:-1, 0] * (feat_3[1:, 0] - feat_3[:-1, 0]))\n",
    "                        )\n",
    "        return u, pred_physics\n",
    "\n",
    "    def forward(self, X, flag, adv_flag):\n",
    "        # flag to show calculate physics loss or not\n",
    "        self.feature = X[:, :32].clone().detach().requires_grad_(True)\n",
    "        self.feat_1 = X[:, 32].clone().detach().requires_grad_(True).unsqueeze(1)\n",
    "        self.feat_2 = X[:, 33].clone().detach().requires_grad_(True).unsqueeze(1)\n",
    "        self.feat_3 = X[:, 34].clone().detach().requires_grad_(True).unsqueeze(1)\n",
    "\n",
    "        if flag:\n",
    "            u, pred_physics = self.Physics_net(self.feature, self.feat_1, self.feat_2, self.feat_3)\n",
    "            return u, pred_physics\n",
    "        else:\n",
    "            u, hidden_feature = self.regression(X)\n",
    "            return u, hidden_feature\n",
    "\n",
    "    def function(self, X, train_out):\n",
    "        u, _ = self.regression(X, adv_flag=True)\n",
    "        pred_loss = torch.mean(torch.square(u - train_out))\n",
    "        return pred_loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3147e93-a796-4077-b31c-248be2d20914",
   "metadata": {},
   "source": [
    "### Import a Demo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "199f70e4-06d2-4848-9ae3-57deed7785bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T06:22:18.888482500Z",
     "start_time": "2025-07-28T06:22:18.831391700Z"
    }
   },
   "outputs": [],
   "source": [
    "# load an example data for demo\n",
    "import pandas as pd\n",
    "df_demo_data = pd.read_pickle('PPG.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40a95ce-5e05-4499-a4da-27394b896c3f",
   "metadata": {},
   "source": [
    "### Preprocess and Prepare the Train/Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ea0b30448ac105c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import random\n",
    "import torch.utils.data as Data\n",
    "import warnings\n",
    "# Initialize a SEED value to ensure that the random processes in the code can be reproduced.\n",
    "SEED = 123\n",
    "# Call the function with seed value\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\n",
    "# The keys for the beat data (beat_key), the target (out_key), and the features (feat_keys) are defined\n",
    "beat_key = 'bioz_beats'\n",
    "out_key = 'sys'\n",
    "shift = 2.0\n",
    "beta = 1\n",
    "feat_keys = ['phys_feat_1','phys_feat_2','phys_feat_3']\n",
    "\n",
    "# Data scaling of BP, input beats, and input features\n",
    "# This scaler standardizes by removing the mean and scaling to unit variance\n",
    "# This is done to ensure having the same scale, which can improve the performance of machine learning algorithms\n",
    "scaler_out = preprocessing.StandardScaler().fit(df_demo_data[out_key].to_numpy()[:, None])\n",
    "mean_value = scaler_out.mean_\n",
    "std_value = scaler_out.scale_\n",
    "\n",
    "contra_shift = (shift - mean_value) / (std_value ** 2)\n",
    "scaler_beats = preprocessing.StandardScaler().fit(np.concatenate(df_demo_data[beat_key].to_numpy())[:, None])\n",
    "scaler_X = [preprocessing.StandardScaler().fit(df_demo_data[a].to_numpy()[:, None]) for a in feat_keys]\n",
    "\n",
    "# Apply Scaling\n",
    "# The scaled versions of the BP, input beats, and input features are then added to the dataframe\n",
    "df_demo_data.loc[df_demo_data.index, beat_key + '_scaled'] = df_demo_data.apply(\n",
    "    lambda x: np.concatenate(scaler_beats.transform(x[beat_key][:, None])), axis=1).to_numpy()\n",
    "\n",
    "def scale_output(row):\n",
    "    output = np.array([row[out_key]])[:, None]\n",
    "    output = output.reshape(-1, 1)\n",
    "    scaled_output = scaler_out.transform(output)\n",
    "    return np.concatenate(scaled_output)[0]\n",
    "\n",
    "df_demo_data[out_key + '_scaled'] = df_demo_data.apply(scale_output, axis=1).to_numpy()\n",
    "\n",
    "# df_demo_data.loc[df_demo_data.index, out_key + '_scaled'] = df_demo_data.apply(\n",
    "#     lambda x: np.concatenate(scaler_out.transform(np.array([x[out_key]])[:, None]))[0], axis=1).to_numpy()\n",
    "\n",
    "def transform_scaler_X(x, tmp_key, tmp_count):\n",
    "    value = np.array([x[tmp_key]])[:, None]\n",
    "    value = value.reshape(-1, 1)\n",
    "    scaled_value = scaler_X[tmp_count].transform(value)\n",
    "    concatenated_value = np.concatenate(scaled_value)\n",
    "    return concatenated_value\n",
    "\n",
    "for tmp_key, tmp_count in zip(feat_keys, range(len(feat_keys))):\n",
    "    # df_demo_data.loc[df_demo_data.index, tmp_key + '_scaled'] = df_demo_data.apply(\n",
    "    #     lambda x: np.concatenate(scaler_X[tmp_count].transform(np.array([x[tmp_key]])[:, None])), axis=1).to_numpy()\n",
    "    df_demo_data[tmp_key + '_scaled'] = df_demo_data.apply(\n",
    "        lambda x, key=tmp_key, count=tmp_count: transform_scaler_X(x, key, count), axis=1).to_numpy()\n",
    "# Fetch scaled feature names\n",
    "X_keys = [a + '_scaled' for a in feat_keys]\n",
    "\n",
    "# Prepare train/test using minimal training the BP\n",
    "# Fetch data shapes\n",
    "length_seq_x = df_demo_data.apply(lambda x: len(x[beat_key + '_scaled']), axis=1).unique()[0]\n",
    "\n",
    "# Set the length of the target to 1\n",
    "length_seq_y = 1\n",
    "\n",
    "# Start with all points\n",
    "# Reshape the scaled beat data into a 2D array where each row corresponds to a sample and each column corresponds to a time point in the beat sequence\n",
    "# The same is done for the features and the target\n",
    "all_beats = np.reshape(np.concatenate(df_demo_data[beat_key + '_scaled'].values), (len(df_demo_data), length_seq_x))\n",
    "[all_feat1, all_feat2, all_feat3] = [df_demo_data[a].values[:, None] for a in X_keys]\n",
    "all_out = df_demo_data[out_key + '_scaled'].values[:, None]\n",
    "\n",
    "# Used only for plotting purposes\n",
    "out_max_rescaled = np.concatenate(scaler_out.inverse_transform(all_out[:, 0][:, None])).max()\n",
    "out_min_rescaled = np.concatenate(scaler_out.inverse_transform(all_out[:, 0][:, None])).min()\n",
    "# Given different trials have time gaps, ignore first 3 instances from indices to prevent discontiunity in training\n",
    "list_all_length = [0]\n",
    "for _, df_tmp in df_demo_data.groupby(['trial_id']):\n",
    "    list_all_length.append(len(df_tmp))\n",
    "ix_ignore_all = np.concatenate(np.array([np.arange(a, a + 3, 1) for a in list(np.cumsum(list_all_length)[:-1])]))\n",
    "# Update the final indices set\n",
    "ix_all = list(set(np.arange(len(df_demo_data))) - set(ix_ignore_all))\n",
    "\n",
    "# Separate train/test based on minimal training criterion\n",
    "random.seed(0)\n",
    "bp_dist = df_demo_data[out_key].values\n",
    "\n",
    "# Find indices for train and test datasets\n",
    "# The target values are sorted in ascending order, and the sorted indices are split into multiple subsets\n",
    "# For each subset, a random index is selected as a training index\n",
    "ix_split = np.split([a for a in np.argsort(bp_dist) if a not in set(ix_ignore_all)], np.cumsum(\n",
    "    np.histogram(bp_dist[ix_all], bins=np.arange(bp_dist[ix_all].min(), bp_dist[ix_all].max(), 1))[0]))\n",
    "ix_train = [random.Random(4).choice(a) if len(a) > 0 else -1 for a in ix_split]\n",
    "ix_train = list(set(ix_train) - set([-1]))\n",
    "# Test set is all remaining points not used for training\n",
    "ix_test = list(set(ix_all) - set(ix_train))\n",
    "\n",
    " # Build train and test datasets based on the indices\n",
    "train_beats = all_beats[ix_train, :]\n",
    "test_beats = all_beats[ix_test, :]\n",
    "[train_feat1, train_feat2, train_feat3] = [all_feat1[ix_train, :], all_feat2[ix_train, :], all_feat3[ix_train, :]]\n",
    "[test_feat1, test_feat2, test_feat3] = [all_feat1[ix_test, :], all_feat2[ix_test, :], all_feat3[ix_test, :]]\n",
    "train_out = all_out[ix_train, :]\n",
    "test_out = all_out[ix_test, :]\n",
    "train_out = [float(item) for item in train_out]\n",
    "test_out = [float(item) for item in test_out]\n",
    "train_out = torch.tensor(train_out, dtype=torch.float32)\n",
    "test_out = torch.tensor(test_out, dtype=torch.float32)\n",
    "\n",
    "train_feat1 = [float(item) for item in train_feat1]\n",
    "train_feat2 = [float(item) for item in train_feat2]\n",
    "train_feat3 = [float(item) for item in train_feat3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4efea98ceb6320",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Define model input tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ab85496f-ad0e-4413-8ad5-9c84f38ba47e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T06:22:23.114484300Z",
     "start_time": "2025-07-28T06:22:23.056576800Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# The training, testing, and all data are converted to TensorFlow tensors\n",
    "# The tensors for the different datasets are grouped into lists \n",
    "model_inp = torch.tensor(train_beats, dtype=torch.float32)\n",
    "feat1_inp = torch.tensor(train_feat1, dtype=torch.float32)\n",
    "feat2_inp = torch.tensor(train_feat2, dtype=torch.float32)\n",
    "feat3_inp = torch.tensor(train_feat3, dtype=torch.float32)\n",
    "\n",
    "inp_feat1 = feat1_inp.unsqueeze(1)\n",
    "inp_feat2 = feat2_inp.unsqueeze(1)\n",
    "inp_feat3 = feat3_inp.unsqueeze(1)\n",
    "train_out = train_out.unsqueeze(1)\n",
    "test_out = test_out.unsqueeze(1)\n",
    "\n",
    "\n",
    "inp_comb = torch.cat((model_inp, inp_feat1, inp_feat2, inp_feat3), dim=1)\n",
    "input_comb_np = inp_comb.clone().detach().numpy()\n",
    "\n",
    "train_dataset = Data.TensorDataset(inp_comb, train_out)\n",
    "train_data_iter = Data.DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "\n",
    "test_feat1 = [float(item) for item in test_feat1]\n",
    "test_feat2 = [float(item) for item in test_feat2]\n",
    "test_feat3 = [float(item) for item in test_feat3]\n",
    "\n",
    "model_inp_test = torch.tensor(test_beats, dtype=torch.float32)\n",
    "feat1_inp_test = torch.tensor(test_feat1, dtype=torch.float32)\n",
    "feat2_inp_test = torch.tensor(test_feat2, dtype=torch.float32)\n",
    "feat3_inp_test = torch.tensor(test_feat3, dtype=torch.float32)\n",
    "\n",
    "\n",
    "feat1_inp_test = feat1_inp_test.unsqueeze(1)\n",
    "feat2_inp_test = feat2_inp_test.unsqueeze(1)\n",
    "feat3_inp_test = feat3_inp_test.unsqueeze(1)\n",
    "\n",
    "inp_comb_test = torch.cat((model_inp_test, feat1_inp_test, feat2_inp_test, feat3_inp_test), dim=1)\n",
    "\n",
    "all_feat1 = [float(item) for item in all_feat1]\n",
    "all_feat2 = [float(item) for item in all_feat2]\n",
    "all_feat3 = [float(item) for item in all_feat3]\n",
    "\n",
    "model_inp_all = torch.tensor(all_beats, dtype=torch.float32)\n",
    "feat1_inp_all = torch.tensor(all_feat1, dtype=torch.float32)\n",
    "feat2_inp_all = torch.tensor(all_feat2, dtype=torch.float32)\n",
    "feat3_inp_all = torch.tensor(all_feat3, dtype=torch.float32)\n",
    "\n",
    "feat1_inp_all = feat1_inp_all.unsqueeze(1)\n",
    "feat2_inp_all = feat2_inp_all.unsqueeze(1)\n",
    "feat3_inp_all = feat3_inp_all.unsqueeze(1)\n",
    "\n",
    "inp_comb_all = torch.cat((model_inp_all, feat1_inp_all, feat2_inp_all, feat3_inp_all), dim=1)\n",
    "ix_all = torch.tensor(ix_all)\n",
    "ix_train = torch.tensor(ix_train)\n",
    "ix_test = torch.tensor(ix_test)\n",
    "\n",
    "test_dataset = Data.TensorDataset(inp_comb_test, test_out)\n",
    "test_data_iter = Data.DataLoader(test_dataset, batch_size=len(inp_comb), drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e868349-c5ed-4c6c-9b2a-666e84cd1439",
   "metadata": {},
   "source": [
    "### Train PITN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7543d519-1fd8-47c3-bee8-2fd9d2afe632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PITN model training started\n",
      "epoch: 0, time: 0.72, loss_dnn:1.856, loss_physics: 0.04569999873638153, test_loss: 2.9440460205078125\n",
      "epoch: 100, time: 0.41, loss_dnn:0.1166, loss_physics: 0.18199999630451202, test_loss: 0.6982888579368591\n",
      "epoch: 200, time: 0.41, loss_dnn:0.0261, loss_physics: 0.11720000207424164, test_loss: 0.690618634223938\n"
     ]
    }
   ],
   "source": [
    "configs = Configs()\n",
    "model_PITN = PITN(configs)\n",
    "import time\n",
    "\n",
    "# A Deep Neural Network model is initialized with the dimension of the beats, the diemnsion of each feature, and the number of neurons in the first dense layer\n",
    "N0 = 200\n",
    "\n",
    "x_train, x_boundary, u_boundary = training_data_latin_hypercube(inp_comb, train_out, N_inner=N0)\n",
    "x_adv = np.array([]).reshape((0, 35))\n",
    "x_train = np.vstack([x_train, x_adv])\n",
    "# No need to retrain, directly generate adversarial samples\n",
    "x_adv = generate_attack_samples(model_PITN, device, x_train, N0, train_out)\n",
    "# using diffusion to generate adversarial samples\n",
    "foward_diffusion = diffusion_foward()\n",
    "x_diffusion = foward_diffusion.q_sample(x_train, torch.tensor([20]))\n",
    "\n",
    "# Two lists are initialized to keep track of the training and testing loss during each epoch\n",
    "loss_list_pinn = []\n",
    "loss_test = []\n",
    "test_loss_list_pinn = []\n",
    "loss_total_epoch = []\n",
    "loss_physics_epoch = []\n",
    "loss_dnn_epoch = []\n",
    "criterion = MultiPosConLoss()\n",
    "print(\"PITN model training started\")\n",
    "optimizer = optim.Adam(model_PITN.parameters(), lr=10e-4)\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "# Two lists are initialized to keep track of the training and testing loss during each epoch\n",
    "epochs = 2000\n",
    "inp_comb_adv = x_adv\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    train_l_sum = 0.0\n",
    "    optimizer.zero_grad()\n",
    "    # Traditional out\n",
    "    model_PITN.to(device=device)\n",
    "    # train on clean data\n",
    "    # if inp_comb and train_out are not tensor, then turn them into tensor\n",
    "    if not torch.is_tensor(inp_comb):\n",
    "        inp_comb = torch.tensor(inp_comb, dtype=torch.float32)\n",
    "    if not torch.is_tensor(train_out):\n",
    "        train_out = torch.tensor(train_out, dtype=torch.float32)\n",
    "    inp_comb, train_out = inp_comb.to(device=device), train_out.to(device=device)\n",
    "    # model_dnn_pinn的参数意思是，输入数据，是否计算physics loss，是否使用auxiliary BN\n",
    "    output, feature_clean = model_PITN(inp_comb, False, False)\n",
    "    loss_dnn_clean = output - train_out\n",
    "    loss_dnn_clean = torch.mean(torch.square(loss_dnn_clean))\n",
    "\n",
    "\n",
    "    loss_dnn = loss_dnn_clean\n",
    "\n",
    "    # Physics loss\n",
    "    inp_comb_all = inp_comb_all.to(device=device)\n",
    "    y, pred_physics = model_PITN(inp_comb_all, True, False)\n",
    "    physics_loss_ini = pred_physics - y[1:, 0]\n",
    "    physics_loss = torch.mean(torch.square(physics_loss_ini[ix_all[:-1].view(-1, 1)]))\n",
    "\n",
    "    # physics_loss = K.mean(K.square(tf.gather_nd(physics_loss_ini, indices=np.array(ix_all[:-1])[:, None])))\n",
    "    loss_total = loss_dnn + physics_loss * beta\n",
    "    loss_total_epoch.append(np.round(loss_total.cpu().detach().numpy(), 4))\n",
    "    loss_physics_epoch.append(np.round(physics_loss.cpu().detach().numpy(), 4))\n",
    "    loss_dnn_epoch.append(np.round(loss_dnn.cpu().detach().numpy(), 4))\n",
    "\n",
    "    loss_total.backward()\n",
    "    optimizer.step()\n",
    "    train_l_sum += loss_total.item()\n",
    "    loss_list_pinn.append(float(loss_dnn.item()))\n",
    "    loss_final = np.min(loss_list_pinn)\n",
    "\n",
    "    # model evaluation\n",
    "    inp_comb_test, test_out = inp_comb_test.to(device=device), test_out.to(device=device)\n",
    "    pred_out, _ = model_PITN(inp_comb_test, False, False)\n",
    "    test_loss = pred_out - test_out\n",
    "    test_loss = torch.mean(torch.square(test_loss))\n",
    "    # test_loss_list_pinn.append(float(test_loss))\n",
    "    loss_test.append(float(test_loss))\n",
    "    \n",
    "    \n",
    "    end = time.time()\n",
    "    # print every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(\n",
    "            \"epoch: {}, time: {}, loss_dnn:{}, loss_physics: {}, test_loss: {}\".format(epoch, round(end - start, 2),\n",
    "                                                                                       np.round(loss_final, 4),\n",
    "                                                                                       np.round(\n",
    "                                                                                           physics_loss.cpu().detach().numpy(),\n",
    "                                                                                           4), test_loss))\n",
    "\n",
    "    # if epoch == epochs - 1:\n",
    "    if (loss_final <= 0.01) | (epoch == epochs - 1):\n",
    "        # wandb.finish()\n",
    "        torch.save(model_PITN.state_dict(),\n",
    "                   \"PITN.pth\")\n",
    "        np.save('PITN_test_loss.npy', loss_test)\n",
    "        np.save('PITN_train_loss.npy', loss_total_epoch)\n",
    "        print(\"PITN model training Completed. Epoch %d/%d\" % (\n",
    "            epoch, epochs))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c83887-d459-4504-9904-146bac14cfb3",
   "metadata": {},
   "source": [
    "### Train DPiKAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc8604c88361d51b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPiKAN model training started\n",
      "epoch: 0, time: 0.35, loss_dnn:1.5506, loss_physics: 0.006200000178068876, test_loss: 121.6598129272461\n",
      "epoch: 100, time: 0.24, loss_dnn:0.7845, loss_physics: 0.1054999977350235, test_loss: 0.8992868065834045\n",
      "epoch: 200, time: 0.26, loss_dnn:0.4311, loss_physics: 0.1777999997138977, test_loss: 0.8298974633216858\n",
      "epoch: 300, time: 0.27, loss_dnn:0.2661, loss_physics: 0.20399999618530273, test_loss: 0.7856473922729492\n",
      "epoch: 400, time: 0.31, loss_dnn:0.1686, loss_physics: 0.22100000083446503, test_loss: 0.7733451128005981\n",
      "epoch: 500, time: 0.25, loss_dnn:0.1194, loss_physics: 0.1889999955892563, test_loss: 0.7749971747398376\n",
      "epoch: 600, time: 0.3, loss_dnn:0.0706, loss_physics: 0.1809999942779541, test_loss: 0.7448967099189758\n",
      "epoch: 700, time: 0.24, loss_dnn:0.0554, loss_physics: 0.16300000250339508, test_loss: 0.7306909561157227\n",
      "epoch: 800, time: 0.24, loss_dnn:0.0369, loss_physics: 0.14830000698566437, test_loss: 0.7078142762184143\n",
      "epoch: 900, time: 0.31, loss_dnn:0.0336, loss_physics: 0.14159999787807465, test_loss: 0.7057144045829773\n",
      "epoch: 1000, time: 0.31, loss_dnn:0.0316, loss_physics: 0.1459999978542328, test_loss: 0.721611499786377\n",
      "epoch: 1100, time: 0.32, loss_dnn:0.0234, loss_physics: 0.11569999903440475, test_loss: 0.7102882266044617\n",
      "epoch: 1200, time: 0.32, loss_dnn:0.0221, loss_physics: 0.13920000195503235, test_loss: 0.6906331181526184\n",
      "epoch: 1300, time: 0.28, loss_dnn:0.0161, loss_physics: 0.11580000072717667, test_loss: 0.7334402203559875\n",
      "epoch: 1400, time: 0.27, loss_dnn:0.0161, loss_physics: 0.1062999963760376, test_loss: 0.7012428045272827\n",
      "epoch: 1500, time: 0.24, loss_dnn:0.0161, loss_physics: 0.10869999974966049, test_loss: 0.7060166597366333\n",
      "epoch: 1600, time: 0.3, loss_dnn:0.0161, loss_physics: 0.09860000014305115, test_loss: 0.6891377568244934\n",
      "epoch: 1700, time: 0.27, loss_dnn:0.0161, loss_physics: 0.1111999973654747, test_loss: 0.6976855397224426\n",
      "epoch: 1800, time: 0.27, loss_dnn:0.0161, loss_physics: 0.09860000014305115, test_loss: 0.689060389995575\n",
      "epoch: 1900, time: 0.28, loss_dnn:0.0133, loss_physics: 0.10180000215768814, test_loss: 0.6907896399497986\n",
      "DPiKAN model training Completed. Epoch 1999/2000\n"
     ]
    }
   ],
   "source": [
    "configs = Configs()\n",
    "model_DPiKAN = DPiKAN(configs)\n",
    "\n",
    "# Two lists are initialized to keep track of the training and testing loss during each epoch\n",
    "loss_list_pinn = []\n",
    "loss_test = []\n",
    "test_loss_list_pinn = []\n",
    "loss_total_epoch = []\n",
    "loss_physics_epoch = []\n",
    "loss_dnn_epoch = []\n",
    "print(\"DPiKAN model training started\")\n",
    "optimizer = optim.Adam(model_DPiKAN.parameters(), lr=10e-4)\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "# Two lists are initialized to keep track of the training and testing loss during each epoch\n",
    "epochs = 2000\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    train_l_sum = 0.0\n",
    "    optimizer.zero_grad()\n",
    "    # Traditional out\n",
    "    model_DPiKAN.to(device=device)\n",
    "    # train on clean data\n",
    "    # if inp_comb and train_out are not tensor, then turn them into tensor\n",
    "    if not torch.is_tensor(inp_comb):\n",
    "        inp_comb = torch.tensor(inp_comb, dtype=torch.float32)\n",
    "    if not torch.is_tensor(train_out):\n",
    "        train_out = torch.tensor(train_out, dtype=torch.float32)\n",
    "    inp_comb, train_out = inp_comb.to(device=device), train_out.to(device=device)\n",
    "    # model_dnn_pinn的参数意思是，输入数据，是否计算physics loss，是否使用auxiliary BN\n",
    "    output = model_DPiKAN(inp_comb, False, False)\n",
    "    loss_dnn_clean = output - train_out\n",
    "    loss_dnn_clean = torch.mean(torch.square(loss_dnn_clean))\n",
    "\n",
    "\n",
    "    loss_dnn = loss_dnn_clean\n",
    "\n",
    "    # Physics loss\n",
    "    inp_comb_all = inp_comb_all.to(device=device)\n",
    "    y, pred_physics = model_DPiKAN(inp_comb_all, True, False)\n",
    "    physics_loss_ini = pred_physics - y[1:, 0]\n",
    "    physics_loss = torch.mean(torch.square(physics_loss_ini[ix_all[:-1].view(-1, 1)]))\n",
    "\n",
    "    # physics_loss = K.mean(K.square(tf.gather_nd(physics_loss_ini, indices=np.array(ix_all[:-1])[:, None])))\n",
    "    loss_total = loss_dnn + physics_loss \n",
    "\n",
    "    loss_total.backward()\n",
    "    optimizer.step()\n",
    "    train_l_sum += loss_total.item()\n",
    "    loss_list_pinn.append(float(loss_dnn.item()))\n",
    "    loss_final = np.min(loss_list_pinn)\n",
    "\n",
    "    # model evaluation\n",
    "    inp_comb_test, test_out = inp_comb_test.to(device=device), test_out.to(device=device)\n",
    "    pred_out = model_DPiKAN(inp_comb_test, False, False)\n",
    "    test_loss = pred_out - test_out\n",
    "    test_loss = torch.mean(torch.square(test_loss))\n",
    "    # test_loss_list_pinn.append(float(test_loss))\n",
    "    loss_test.append(float(test_loss))\n",
    "    \n",
    "    \n",
    "    end = time.time()\n",
    "    # print every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(\n",
    "            \"epoch: {}, time: {}, loss_dnn:{}, loss_physics: {}, test_loss: {}\".format(epoch, round(end - start, 2),\n",
    "                                                                                       np.round(loss_final, 4),\n",
    "                                                                                       np.round(\n",
    "                                                                                           physics_loss.cpu().detach().numpy(),\n",
    "                                                                                           4), test_loss))\n",
    "\n",
    "\n",
    "    # if epoch == epochs - 1:\n",
    "    if (loss_final <= 0.01) | (epoch == epochs - 1):\n",
    "        # wandb.finish()\n",
    "        torch.save(model_DPiKAN.state_dict(),\n",
    "                   \"DPiKAN.pth\")\n",
    "        np.save('DPiKAN_test_loss.npy', loss_test)\n",
    "        np.save('DPiKAN_train_loss.npy', loss_total_epoch)\n",
    "        print(\"DPiKAN model training Completed. Epoch %d/%d\" % (\n",
    "            epoch, epochs))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f124eaa40064363",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Evaluate DPiKAN and PITN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7776218f-592d-4278-9ed6-da9326f2fd66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T12:50:19.931194800Z",
     "start_time": "2025-11-11T12:50:19.351480400Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### PITN Performance ####\n",
      "Corr: 0.59,  RMSE: 5.5\n",
      "#### DPiKAN Performance ####\n",
      "Corr: 0.62,  RMSE: 5.2\n"
     ]
    }
   ],
   "source": [
    "configs = Configs()\n",
    "model_DPiKAN = DPiKAN(configs)\n",
    "model_DPiKAN.eval()\n",
    "model_DPiKAN.to(device=device)\n",
    "model_DPiKAN.load_state_dict(torch.load(\"DPiKAN.pth\"))\n",
    "\n",
    "model_PITN = PITN(configs)\n",
    "model_PITN.eval()\n",
    "model_PITN.to(device=device)\n",
    "model_PITN.load_state_dict(torch.load(\"PITN.pth\"))\n",
    "inp_comb_test = inp_comb_test.to(device)\n",
    "\n",
    "if torch.is_tensor(test_out):\n",
    "    test_out = test_out.cpu().numpy()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_out_PITN, _ = model_PITN(inp_comb_test, False, False)\n",
    "    pred_out_DPiKAN = model_DPiKAN(inp_comb_test, False, False)\n",
    "\n",
    "pred_out_PITN = pred_out_PITN.cpu().numpy()\n",
    "pred_out_DPiKAN = pred_out_DPiKAN.cpu().numpy()\n",
    "\n",
    "np.save('PITN_pred_out.npy', pred_out_PITN)\n",
    "np.save('DPiKAN_pred_out.npy', pred_out_DPiKAN)\n",
    "\n",
    "if not isinstance(test_out, np.ndarray):  # 如果 test_out 不是 numpy 数组\n",
    "    test_out = test_out.numpy()  \n",
    "\n",
    "test_out = np.array(test_out).reshape(-1, 1)\n",
    "corr_PITN = np.corrcoef(np.concatenate(test_out[:]), np.concatenate(pred_out_PITN)[:])[0][1]\n",
    "rmse_PITN = np.sqrt(np.mean(np.square\n",
    "                           (np.concatenate(scaler_out.inverse_transform(np.concatenate(test_out)[:][:, None]))-\n",
    "                            np.concatenate(scaler_out.inverse_transform(np.concatenate(pred_out_PITN)[:][:, None])))))\n",
    "\n",
    "\n",
    "corr_DPiKAN = np.corrcoef(np.concatenate(test_out)[:], np.concatenate(pred_out_DPiKAN)[:])[0][1]\n",
    "rmse_DPiKAN = np.sqrt(np.mean(np.square(\n",
    "    np.concatenate(scaler_out.inverse_transform(np.concatenate(test_out)[:][:, None]))-\n",
    "    np.concatenate(scaler_out.inverse_transform(np.concatenate(pred_out_DPiKAN)[:][:, None])))))\n",
    "\n",
    "print('#### PITN Performance ####')\n",
    "print('Corr: %.2f,  RMSE: %.1f'%(corr_PITN, rmse_PITN))\n",
    "\n",
    "print('#### DPiKAN Performance ####')\n",
    "print('Corr: %.2f,  RMSE: %.1f'%(corr_DPiKAN, rmse_DPiKAN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88634652240a6cda",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6356413c-55f0-482e-a15a-9aeeba5294bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T09:06:21.253929600Z",
     "start_time": "2025-07-27T09:06:21.094402800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"c7a2e465-954d-4dab-9076-2bde98f1f7bf\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"c7a2e465-954d-4dab-9076-2bde98f1f7bf\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.2.2.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "          for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"c7a2e465-954d-4dab-9076-2bde98f1f7bf\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"c7a2e465-954d-4dab-9076-2bde98f1f7bf\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.2.2.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"c7a2e465-954d-4dab-9076-2bde98f1f7bf\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"bc111cbc-51c8-4007-be6f-a48f28eeb587\" data-root-id=\"p1030\" style=\"display: contents;\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "  const docs_json = {\"bccd7616-2a55-420c-ab12-3afa9877c46f\":{\"version\":\"3.2.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1030\",\"attributes\":{\"width\":770,\"height\":400,\"x_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1032\"},\"y_range\":{\"type\":\"object\",\"name\":\"Range1d\",\"id\":\"p1039\",\"attributes\":{\"start\":83.07833333333333,\"end\":149.233}},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1040\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1041\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1037\"},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1065\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1059\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1060\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1061\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[661],\"dtype\":\"int32\",\"order\":\"little\"}],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[661],\"dtype\":\"float32\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1066\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1067\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1062\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":7},\"line_color\":{\"type\":\"value\",\"value\":null},\"fill_color\":{\"type\":\"value\",\"value\":\"#D55E00\"},\"hatch_color\":{\"type\":\"value\",\"value\":\"#D55E00\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1063\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":7},\"line_color\":{\"type\":\"value\",\"value\":null},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"value\",\"value\":\"#D55E00\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_color\":{\"type\":\"value\",\"value\":\"#D55E00\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1064\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":7},\"line_color\":{\"type\":\"value\",\"value\":null},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"value\",\"value\":\"#D55E00\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_color\":{\"type\":\"value\",\"value\":\"#D55E00\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1076\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1070\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1071\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1072\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[661],\"dtype\":\"int32\",\"order\":\"little\"}],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[661],\"dtype\":\"float32\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1077\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1078\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1073\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":7},\"line_color\":{\"type\":\"value\",\"value\":null},\"fill_color\":{\"type\":\"value\",\"value\":\"#009E73\"},\"hatch_color\":{\"type\":\"value\",\"value\":\"#009E73\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1074\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":7},\"line_color\":{\"type\":\"value\",\"value\":null},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"value\",\"value\":\"#009E73\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_color\":{\"type\":\"value\",\"value\":\"#009E73\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p1075\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"size\":{\"type\":\"value\",\"value\":7},\"line_color\":{\"type\":\"value\",\"value\":null},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"value\",\"value\":\"#009E73\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_color\":{\"type\":\"value\",\"value\":\"#009E73\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1086\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1080\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1081\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1082\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690]],[\"y\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[691],\"dtype\":\"float64\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1087\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1088\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1083\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_width\":3,\"line_dash\":[6]}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1084\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_alpha\":0.1,\"line_width\":3,\"line_dash\":[6]}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1085\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_alpha\":0.2,\"line_width\":3,\"line_dash\":[6]}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1038\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p1052\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p1053\"},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p1054\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p1055\",\"attributes\":{\"syncable\":false,\"level\":\"overlay\",\"visible\":false,\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"bottom_units\":\"canvas\",\"top_units\":\"canvas\",\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5}}}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p1056\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p1057\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p1058\"}]}},\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1047\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1048\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1049\"},\"axis_label\":\"SBP (mmHg)\",\"axis_label_text_font\":\"Times New Roman\",\"axis_label_text_font_size\":\"25pt\",\"axis_label_text_font_style\":\"bold\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1050\"},\"major_label_text_font_size\":\"25pt\",\"major_label_text_font_style\":\"bold\"}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1042\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1043\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1044\"},\"axis_label\":\"Beat time (s)\",\"axis_label_text_font\":\"Times New Roman\",\"axis_label_text_font_size\":\"25pt\",\"axis_label_text_font_style\":\"bold\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1045\"},\"major_label_text_font_size\":\"25pt\",\"major_label_text_font_style\":\"bold\"}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1046\",\"attributes\":{\"axis\":{\"id\":\"p1042\"}}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1051\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1047\"}}},{\"type\":\"object\",\"name\":\"Legend\",\"id\":\"p1068\",\"attributes\":{\"items\":[{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1069\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"DPiKAN\"},\"renderers\":[{\"id\":\"p1065\"}]}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1079\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"PITN\"},\"renderers\":[{\"id\":\"p1076\"}]}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1089\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"True BP\"},\"renderers\":[{\"id\":\"p1086\"}]}}]}}]}}]}};\n",
       "  const render_items = [{\"docid\":\"bccd7616-2a55-420c-ab12-3afa9877c46f\",\"roots\":{\"p1030\":\"bc111cbc-51c8-4007-be6f-a48f28eeb587\"},\"root_ids\":[\"p1030\"]}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    let attempts = 0;\n",
       "    const timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "p1030"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_out_DPiKAN = np.load('DPiKAN_pred_out.npy')\n",
    "pred_out_PITN = np.load('PITN_pred_out.npy')\n",
    "ix_test = ix_test.cpu().numpy() if torch.is_tensor(ix_test) else ix_test\n",
    "s=figure(width=770,height=400,y_range=(out_min_rescaled-20,out_max_rescaled+20))\n",
    "s.scatter(ix_test, np.concatenate(scaler_out.inverse_transform(pred_out_DPiKAN)), size=7, line_color=None, color=palettes.Colorblind8[5], legend_label='DPiKAN')\n",
    "s.scatter(ix_test, np.concatenate(scaler_out.inverse_transform(pred_out_PITN)), size=7, line_color=None, color=palettes.Colorblind8[3], legend_label='PITN')\n",
    "s.line(list(range(len(df_demo_data))),np.concatenate(scaler_out.inverse_transform(all_out[:,0][:,None])),line_width=3,line_color='black',line_alpha=1,line_dash='dashed',legend_label='True BP')\n",
    "s.xaxis.axis_label='Beat time (s)'\n",
    "s.yaxis.axis_label='SBP (mmHg)'\n",
    "\n",
    "output_notebook() \n",
    "figure_settings(s)\n",
    "show(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5813fc61fe3642",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Calculate Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4096fdd8e3e5ba53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T08:25:49.480284Z",
     "start_time": "2025-11-12T08:25:49.427231200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool1d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "DPiKAN: flops: 237600.0, params: 8226.0\n",
      "-----------------------------------------------------------\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "PITN: flops: 299978819.0, params: 299988100.0\n"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "configs = Configs()\n",
    "model_DPiKAN = DPiKAN(configs)\n",
    "model_PITN = PITN(configs)\n",
    "input_seq = torch.randn(1, 35, dtype=torch.float)\n",
    "flops_DPiKAN_test, params_DPiKAN_test = profile(model_DPiKAN, inputs=(input_seq, False, False))\n",
    "print(\"DPiKAN: flops: {}, params: {}\".format(flops_DPiKAN_test, params_DPiKAN_test))\n",
    "\n",
    "print(\"-----------------------------------------------------------\")\n",
    "\n",
    "flops_PITN, params_PITN = profile(model_PITN, inputs=(input_seq, False, False,))\n",
    "print(\"PITN: flops: {}, params: {}\".format(flops_PITN, params_PITN))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cedf2d8b0464f5a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
